{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f7f43f0-f16e-49ce-8308-9dd27ecc3c45",
   "metadata": {},
   "source": [
    "## Salience F0 estimation\n",
    "A step-by-step guide through the salience-based F0 estimation [3] algorithm. This notebook is part of **libf0 -  A Python Library for F0-Estimation in Music Recordings**.\n",
    "\n",
    "[3] Justin Salamon and Emilia Gómez. Melody Extraction From Polyphonic Music Signals Using Pitch Contour Characteristics. IEEE Transactions on Audio, Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, Aug. 2012."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ab0273-5e22-461b-a7ec-2c124c8da72c",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    "* Take FMP notebooks https://www.audiolabs-erlangen.de/resources/MIR/FMP/C8/C8S2_SalienceRepresentation.html + https://www.audiolabs-erlangen.de/resources/MIR/FMP/C8/C8S2_FundFreqTracking.html and update the code to reflect the libf0 version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16319eed",
   "metadata": {},
   "source": [
    "Available Implementations:\n",
    "* https://www.upf.edu/web/mtg/melodia\n",
    "* https://essentia.upf.edu/reference/std_PredominantPitchMelodia.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7322f23-a3d8-4f06-9d61-8ff454cef160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from scipy import ndimage, linalg\n",
    "\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed49c2e8-bea6-4ed1-9846-1e9202746081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load demo audio (a throat microphone recording of a soprano singer)\n",
    "fn_wav = \"../data/DCS_LI_QuartetB_Take03_S1_LRX_excerpt.wav\"\n",
    "x, Fs = librosa.load(fn_wav, sr=22050)\n",
    "ipd.display(ipd.Audio(x, rate=Fs, normalize=True)) # audio playback\n",
    "\n",
    "# set all parameters for YIN\n",
    "N = 2048 # frame size of the algorithm in samples\n",
    "H = 256 # hop size of the algorithm in samples\n",
    "F_min = 55.0 # minimum frequency of interest in Hz\n",
    "F_max = 1760.0 # maximum frequency of interest in Hz\n",
    "R = 10.0\n",
    "num_harm = 10\n",
    "freq_smooth_len = 11\n",
    "alpha = 0.9\n",
    "gamma = 0.0\n",
    "constraint_region = None\n",
    "tol = 5\n",
    "score_low = 0.01\n",
    "score_high = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc16a737-f642-4879-8afa-80aaad8c1f57",
   "metadata": {},
   "source": [
    "In the following, we visualize the salience-based algorithm step-by-step. First, we compute instantaneous frequencies for a log-frequency magnitude spectrogram representation of our signal and smooth the result on the time axis with a Hann kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9ea757-d07b-4286-abfd-eee08f574aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequency_to_bin_index(F, R, F_ref):\n",
    "    \"\"\"\n",
    "        Binning function with variable frequency resolution\n",
    "        Note: Indexing starts with 0 (opposed to [FMP, Eq. (8.49)])\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    F : float or ndarray\n",
    "        Frequency in Hz\n",
    "    R : float\n",
    "        Frequency resolution in cents (Default value = 10.0)\n",
    "    F_ref : float\n",
    "        Reference frequency in Hz (Default value = 55.0)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        bin_index (int): Index for bin (starting with index 0)\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    [FMP] Notebook: C8/C8S2_SalienceRepresentation.ipynb\n",
    "    \"\"\"\n",
    "    bin_index = np.floor((1200 / R) * np.log2(F / F_ref) + 0.5).astype(np.int64)\n",
    "    return bin_index\n",
    "\n",
    "def compute_y_lf_if_bin_eff(X, Fs, N, H, F_min, F_max, R):\n",
    "    \"\"\"\n",
    "    Binned Log-frequency Spectrogram with variable frequency resolution based on instantaneous frequency,\n",
    "    more efficient implementation than FMP\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray\n",
    "        Complex spectrogram\n",
    "    Fs : int\n",
    "        Sampling rate in Hz\n",
    "    N : int\n",
    "        Window size\n",
    "    H : int\n",
    "        Hop size\n",
    "    F_min : float or int\n",
    "        Minimal frequency\n",
    "    F_max : float or int\n",
    "        Maximal frequency\n",
    "    R : int\n",
    "        Frequency resolution given in cents\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Y_LF_IF_bin : ndarray\n",
    "        Binned log-frequency spectrogram using instantaneous frequency (shape: [freq, time])\n",
    "    F_coef_hertz : ndarray\n",
    "        Frequency axis in Hz\n",
    "    \"\"\"\n",
    "\n",
    "    # calculate number of bins on log frequency axis\n",
    "    B = frequency_to_bin_index(F_max, R, F_min) + 1\n",
    "\n",
    "    # center frequencies of the final bins\n",
    "    F_coef_hertz = F_min * np.power(2, (np.arange(0, B) * R / 1200))\n",
    "\n",
    "    # calculate heterodyned phase increment (hpi)\n",
    "    k = np.arange(X.shape[0]).reshape(-1, 1)\n",
    "    omega = 2 * np.pi * k / N  # center frequency for each bin in rad\n",
    "    hpi = (np.angle(X[:, 1:]) - np.angle(X[:, 0:-1])) - omega * H\n",
    "\n",
    "    # reduce hpi to -pi:pi range\n",
    "    # this is much faster than using the modulo function below, but gives the same result\n",
    "    # hpi = np.mod(hpi + np.pi, 2 * np.pi) - np.pi\n",
    "    hpi = hpi - 2 * np.pi * (np.around((hpi / (2 * np.pi)) + 1) - 1)\n",
    "\n",
    "    # calculate instantaneous frequencies in Hz\n",
    "    inst_f = (omega + hpi / H) * Fs / (2 * np.pi)\n",
    "    # repeat the first time frame to match dimensions of X\n",
    "    inst_f = np.hstack((np.copy(inst_f[:, 0]).reshape(-1, 1), inst_f))\n",
    "\n",
    "    # mask frequencies that are not relevant\n",
    "    mask = np.logical_and(inst_f >= F_min, inst_f < F_max)\n",
    "    inst_f *= mask\n",
    "    # set 0 to nan, so it does stay at nan in the bin assignment calculation\n",
    "    inst_f[np.where(inst_f == 0)] = np.nan\n",
    "\n",
    "    # find which inst_f values belong to which bin\n",
    "    bin_assignment = frequency_to_bin_index(inst_f, R, F_min)\n",
    "    # we map the discarded values to an extra bin that we remove before returning the binned spectrogram\n",
    "    bin_assignment[np.where(np.isnan(inst_f))] = B\n",
    "\n",
    "    # perform binning on power spectrogram for each time frame separately\n",
    "    Y = np.abs(X) ** 2\n",
    "    Y_LF_IF_bin = np.zeros((B+1, Y.shape[1]))\n",
    "    for t in range(Y.shape[1]):\n",
    "        np.add.at(Y_LF_IF_bin[:, t], bin_assignment[:, t], Y[:, t])\n",
    "\n",
    "    return Y_LF_IF_bin[:B, :], F_coef_hertz\n",
    "\n",
    "X = librosa.stft(x, n_fft=N, hop_length=H, win_length=N, pad_mode='constant')\n",
    "Y_LF_IF_bin, F_coef_hertz = compute_y_lf_if_bin_eff(X, Fs, N, H, F_min, F_max, R)\n",
    "\n",
    "Y_LF_IF_bin = ndimage.convolve1d(Y_LF_IF_bin, np.hanning(freq_smooth_len), axis=0, mode='constant')\n",
    "\n",
    "# TODO: nice plot\n",
    "plt.pcolormesh(np.log(Y_LF_IF_bin + 1e-7))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a011d-f8fe-4f39-9472-20203a4e2d6e",
   "metadata": {},
   "source": [
    "From this IF spectrogram, we can compute the salience representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83b57d8-64c0-4df9-a17f-7a83b9036046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_salience_from_logfreq_spec(lf_spec, R, n_harmonics, alpha, beta, gamma, harmonic_win_len=11):\n",
    "    \"\"\"\n",
    "    Compute salience representation using harmonic summation following [1]\n",
    "\n",
    "    [1] J. Salamon and E. Gomez,\n",
    "        \"Melody Extraction From Polyphonic Music Signals Using Pitch Contour Characteristics.\"\n",
    "        IEEE Transactions on Audio, Speech, and Language Processing, vol. 20, no. 6, pp. 1759–1770, Aug. 2012.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lf_spec : ndarray\n",
    "        (F, T) log-spectrogram\n",
    "    R : int\n",
    "        Frequency resolution given in cents\n",
    "    n_harmonics : int\n",
    "        Number of harmonics\n",
    "    alpha : float\n",
    "        Weighting parameter for harmonics\n",
    "    beta : float\n",
    "        Compression parameter for spectrogram magnitudes\n",
    "    gamma : float\n",
    "        Magnitude threshold\n",
    "    harmonic_win_len : int\n",
    "        Length of a frequency weighting window in bins\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Z : ndarray\n",
    "        (F, T) salience representation of the input spectrogram\n",
    "    \"\"\"\n",
    "\n",
    "    # magnitude thresholding and compression\n",
    "    eps = np.finfo(np.float32).eps\n",
    "    threshold_mask = (20 * np.log10(lf_spec/np.max(lf_spec) + eps)) < gamma\n",
    "    lf_spec = lf_spec**beta * threshold_mask\n",
    "\n",
    "    # compute window\n",
    "    max_diff_bins = harmonic_win_len // 2\n",
    "    window = np.cos(np.linspace(-1, 1, 2*max_diff_bins+1)*np.pi/2)**2  # cosine^2 window\n",
    "\n",
    "    # compute indices of harmonics\n",
    "    harmonics = np.round(np.log2(np.arange(1, n_harmonics + 1)) * 1200 / R).astype(int)\n",
    "    weighting_vec = np.zeros((lf_spec.shape[0] + max_diff_bins))\n",
    "\n",
    "    # compute weights\n",
    "    for idx, h in enumerate(harmonics):\n",
    "        if h+harmonic_win_len > len(weighting_vec):\n",
    "            break  # we reached the maximum length available\n",
    "        weighting_vec[h:h+harmonic_win_len] += window * alpha**idx\n",
    "\n",
    "    # correlate lf_spec with the weighting vector on the frequency axis\n",
    "    Z = ndimage.correlate1d(lf_spec, weighting_vec[:],\n",
    "                            axis=0, mode='constant', cval=0, origin=-len(weighting_vec)//2 + max_diff_bins)\n",
    "\n",
    "    # magnitude thresholding and compression\n",
    "    threshold_mask = (20 * np.log10(Z / np.max(Z) + eps)) < gamma\n",
    "    Z = Z ** beta * threshold_mask\n",
    "\n",
    "    return Z\n",
    "\n",
    "Z = compute_salience_from_logfreq_spec(Y_LF_IF_bin, R, n_harmonics=num_harm, alpha=alpha, beta=1, gamma=gamma)\n",
    "\n",
    "# TODO: nice plot\n",
    "plt.pcolormesh(np.log(Z + 1e-7))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d2a331-0088-4b74-9dc7-5b9963cee547",
   "metadata": {},
   "source": [
    "On this representation, we can track a smooth local maximum trajectory using a dynamic programming approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68a7d4b-a53a-49eb-9c23-302eb831893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_transition_matrix(B, tol=0, score_low=0.01, score_high=1.0):\n",
    "    \"\"\"\n",
    "    Generate transition matrix for dynamic programming\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    B : int\n",
    "        Number of bins\n",
    "    tol : int\n",
    "        Tolerance parameter for transition matrix (Default value = 0)\n",
    "    score_low : float\n",
    "        Score (low) for transition matrix (Default value = 0.01)\n",
    "    score_high : float\n",
    "        Score (high) for transition matrix (Default value = 1.0)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    T : ndarray\n",
    "        (B, B) Transition matrix\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    [FMP] Notebook: C8/C8S2_FundFreqTracking.ipynb\n",
    "    \"\"\"\n",
    "\n",
    "    col = np.ones((B,)) * score_low\n",
    "    col[0:tol+1] = np.ones((tol+1, )) * score_high\n",
    "    T = linalg.toeplitz(col)\n",
    "    return T\n",
    "\n",
    "def compute_trajectory_dp(Z, T):\n",
    "    \"\"\"\n",
    "    Trajectory tracking using dynamic programming\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Z : ndarray\n",
    "        Salience representation\n",
    "    T : ndarray\n",
    "        Transisition matrix\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    eta_DP : ndarray\n",
    "        Trajectory indices\n",
    "\n",
    "    See also\n",
    "    --------\n",
    "    [FMP] Notebook: C8/C8S2_FundFreqTracking.ipynb\n",
    "    \"\"\"\n",
    "\n",
    "    B, N = Z.shape\n",
    "    eps_machine = np.finfo(np.float32).eps\n",
    "    Z_log = np.log(Z + eps_machine)\n",
    "    T_log = np.log(T + eps_machine)\n",
    "\n",
    "    E = np.zeros((B, N))\n",
    "    D = np.zeros((B, N))\n",
    "    D[:, 0] = Z_log[:, 0]\n",
    "\n",
    "    for n in np.arange(1, N):\n",
    "        for b in np.arange(0, B):\n",
    "            D[b, n] = np.max(T_log[b, :] + D[:, n-1]) + Z_log[b, n]\n",
    "            E[b, n-1] = np.argmax(T_log[b, :] + D[:, n-1])\n",
    "\n",
    "    # backtracking\n",
    "    eta_DP = np.zeros(N)\n",
    "    eta_DP[N-1] = int(np.argmax(D[:, N-1]))\n",
    "\n",
    "    for n in np.arange(N-2, -1, -1):\n",
    "        eta_DP[n] = E[int(eta_DP[n+1]), n]\n",
    "\n",
    "    return eta_DP.astype(np.int64)\n",
    "\n",
    "T = define_transition_matrix(Z.shape[0], tol=tol, score_low=score_low, score_high=score_high)\n",
    "eta = compute_trajectory_dp(Z, T)\n",
    "\n",
    "traj = F_coef_hertz[eta]\n",
    "traj[eta == -1] = 0\n",
    "\n",
    "# TODO: nice plot\n",
    "plt.plot(traj)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5015c7-c549-4ecd-a2c9-7e382e0d0ea4",
   "metadata": {},
   "source": [
    "And finally, we can derive a confidence in our estimates by extracting the values of the salience representation at the tracked trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a61c4-1bf9-4dd2-9973-d898df7d12cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_max = np.max(Z, axis=0)\n",
    "Z_norm = np.divide(Z, np.ones((Z.shape[0], 1)) * Z_max)\n",
    "sal = Z_norm[eta, np.arange(Z.shape[1])]\n",
    "sal[traj == 0] = 0\n",
    "\n",
    "# TODO: nice plot\n",
    "plt.plot(sal)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
