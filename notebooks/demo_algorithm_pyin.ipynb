{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e61ea723-6a99-44b5-b7fb-191c2c94c632",
   "metadata": {},
   "source": [
    "## pYIN\n",
    "A step-by-step guide through the pYIN [2] algorithm. This notebook is part of **libf0 -  A Python Library for F0-Estimation in Music Recordings**.\n",
    "\n",
    "[2] Matthias Mauch and Simon Dixon. PYIN: A fundamental frequency estimator using probabilistic threshold distributions. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (2014): 659-663."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678efa78-ee46-45b7-b9df-66a0e663b72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "from scipy.special import beta, comb\n",
    "from scipy.stats import triang\n",
    "\n",
    "from libf0 import cumulative_mean_normalized_difference_function, parabolic_interpolation\n",
    "\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad91050-ff65-42fb-849b-c47386dca521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load demo audio (a throat microphone recording of a soprano singer)\n",
    "fn_wav = \"../data/DCS_LI_QuartetB_Take03_S1_LRX_excerpt.wav\"\n",
    "x, Fs = librosa.load(fn_wav, sr=22050)\n",
    "ipd.display(ipd.Audio(x, rate=Fs, normalize=True)) # audio playback\n",
    "\n",
    "# set all parameters for YIN\n",
    "N = 2048 # frame size of the algorithm in samples\n",
    "H = 256 # hop size of the algorithm in samples\n",
    "F_min = 55.0 # minimum frequency of interest in Hz\n",
    "F_max = 1760.0 # maximum frequency of interest in Hz\n",
    "R = 10 # bin resolution of estimates in cents\n",
    "thresholds = np.arange(0.01, 1, 0.01) # different thresholds for multiple runs of YIN\n",
    "beta_params = [1, 18]\n",
    "absolute_min_prob = 0.01\n",
    "voicing_prob = 0.5\n",
    "\n",
    "# extract an example frame for visualization\n",
    "start_time = int(1*Fs) # in samples\n",
    "example_frame = x[start_time:start_time + N]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8dc47b-3c06-4a6f-b7a5-944874bb6fa5",
   "metadata": {},
   "source": [
    "In the following, we visualize the pYIN algorithm for an example frame from our input signal. First, we run YIN (see notebook `demo_algorithm_yin.ipynb`) with multiple thresholds and perform a probabilistic thresholding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c538919-0e88-4efd-bcf6-dbb5d152713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_numba(arr, num): # TODO: remove?\n",
    "    \"\"\"Delete number from array, Numba compatible. Inspired by:\n",
    "        https://stackoverflow.com/questions/53602663/delete-a-row-in-numpy-array-in-numba\n",
    "    \"\"\"\n",
    "    mask = np.zeros(len(arr), dtype=np.int64) == 0\n",
    "    mask[np.where(arr == num)[0]] = False\n",
    "    return arr[mask]\n",
    "\n",
    "def probabilistic_thresholding(cmndf, thresholds, p_min, p_max, absolute_min_prob, F_axis, Fs, beta_distr,\n",
    "                               parabolic_interp=True):\n",
    "    \"\"\"\n",
    "    Probabilistic thresholding of the YIN CMNDF.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cmndf : ndarray\n",
    "        Cumulative Mean Normalized Difference Function\n",
    "    thresholds : ndarray\n",
    "        Array of thresholds for CMNDF\n",
    "    p_min : float\n",
    "        Period corresponding to the lower frequency bound\n",
    "    p_max : float\n",
    "        Period corresponding to the upper frequency bound\n",
    "    absolute_min_prob : float\n",
    "        Probability to chose absolute minimum\n",
    "    F_axis : ndarray\n",
    "        Frequency axis\n",
    "    Fs : float\n",
    "        Sampling rate\n",
    "    beta_distr : ndarray\n",
    "        Beta distribution that defines mapping between thresholds and probabilities\n",
    "    parabolic_interp : bool\n",
    "        Switch to activate/deactivate parabolic interpolation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    O_m : ndarray\n",
    "        Observations for given frame\n",
    "    lag_thr : ndarray\n",
    "        Computed lags for every threshold\n",
    "    val_thr : ndarray\n",
    "        CMNDF values for computed lag\n",
    "    \"\"\"\n",
    "    # restrict search range to interval [p_min:p_max]\n",
    "    cmndf[:p_min] = np.inf\n",
    "    cmndf[p_max:] = np.inf\n",
    "\n",
    "    # find local minima (assuming that cmndf is real in [p_min:p_max], you will always find a minimum,\n",
    "    # at least p_min or p_max)\n",
    "    min_idxs = (np.argwhere((cmndf[1:-1] < cmndf[0:-2]) & (cmndf[1:-1] < cmndf[2:]))).flatten().astype(np.int64) + 1\n",
    "\n",
    "    O_m = np.zeros(2 * len(F_axis))\n",
    "\n",
    "    # return if no minima are found, e.g., when frame is silence\n",
    "    if min_idxs.size == 0:\n",
    "        return O_m, np.ones_like(thresholds)*p_min, np.ones_like(thresholds)\n",
    "\n",
    "    # Optional: Parabolic Interpolation of local minima\n",
    "    if parabolic_interp:\n",
    "        # do not interpolate at the boarders, Numba compatible workaround for np.delete()\n",
    "        min_idxs_interp = delete_numba(min_idxs, np.argwhere(min_idxs == p_min))\n",
    "        min_idxs_interp = delete_numba(min_idxs_interp, np.argwhere(min_idxs_interp == p_max - 1))\n",
    "        p_corr, cmndf[min_idxs_interp] = parabolic_interpolation(cmndf[min_idxs_interp - 1],\n",
    "                                                                 cmndf[min_idxs_interp],\n",
    "                                                                 cmndf[min_idxs_interp + 1])\n",
    "    else:\n",
    "        p_corr = np.zeros_like(min_idxs).astype(np.float64)\n",
    "\n",
    "    # set p_corr=0 at the boarders (no correction done later)\n",
    "    if min_idxs[0] == p_min:\n",
    "        p_corr = np.concatenate((np.array([0.0]), p_corr))\n",
    "\n",
    "    if min_idxs[-1] == p_max - 1:\n",
    "        p_corr = np.concatenate((p_corr, np.array([0.0])))\n",
    "\n",
    "    lag_thr = np.zeros_like(thresholds)\n",
    "    val_thr = np.zeros_like(thresholds)\n",
    "\n",
    "    # loop over all thresholds\n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        # minima below absolute threshold\n",
    "        min_idxs_thr = min_idxs[cmndf[min_idxs] < threshold]\n",
    "\n",
    "        # find first local minimum\n",
    "        if not min_idxs_thr.size:\n",
    "            lag = np.argmin(cmndf)  # choose absolute minimum when no local minimum is found\n",
    "            am_prob = absolute_min_prob\n",
    "            val = np.min(cmndf)\n",
    "        else:\n",
    "            am_prob = 1\n",
    "            lag = np.min(min_idxs_thr)  # choose first local minimum\n",
    "            val = cmndf[lag]\n",
    "\n",
    "            # correct lag\n",
    "            if parabolic_interp:\n",
    "                lag += p_corr[np.argmin(min_idxs_thr)]\n",
    "\n",
    "        # ensure that lag is in [p_min:p_max]\n",
    "        if lag < p_min:\n",
    "            lag = p_min\n",
    "        elif lag >= p_max:\n",
    "            lag = p_max - 1\n",
    "\n",
    "        lag_thr[i] = lag\n",
    "        val_thr[i] = val\n",
    "\n",
    "        idx = np.argmin(np.abs(1200 * np.log2(F_axis / (Fs / lag))))  # quantize estimated period\n",
    "        O_m[idx] += am_prob * beta_distr[i]  # pYIN-Paper, Formula 4/5\n",
    "\n",
    "    return O_m, lag_thr, val_thr\n",
    "\n",
    "def yin_multi_thr(x, Fs, N, H, F_min, F_max, thresholds, beta_distr, absolute_min_prob, F_axis, voicing_prob,\n",
    "                  parabolic_interp=True):\n",
    "    \"\"\"\n",
    "    Applies YIN multiple times on input audio signals using different thresholds for CMNDF.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : ndarray\n",
    "        Input audio signal\n",
    "    Fs : int\n",
    "        Sampling rate\n",
    "    N : int\n",
    "        Window size\n",
    "    H : int\n",
    "        Hop size\n",
    "    F_min : float\n",
    "        Lower frequency bound\n",
    "    F_max : float\n",
    "        Upper frequency bound\n",
    "    thresholds : ndarray\n",
    "        Array of thresholds\n",
    "    beta_distr : ndarray\n",
    "        Beta distribution that defines mapping between thresholds and probabilities\n",
    "    absolute_min_prob :float\n",
    "        Probability to chose absolute minimum\n",
    "    F_axis : ndarray\n",
    "        Frequency axis\n",
    "    voicing_prob : float\n",
    "        Probability of a frame being voiced\n",
    "    parabolic_interp : bool\n",
    "        Switch to activate/deactivate parabolic interpolation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    O : ndarray\n",
    "        Observations based on YIN output\n",
    "    rms : ndarray\n",
    "        Root mean square power\n",
    "    p_orig : ndarray\n",
    "        Original YIN period estimates\n",
    "    val_orig : ndarray\n",
    "        CMNDF values corresponding to original YIN period estimates\n",
    "    \"\"\"\n",
    "\n",
    "    M = int(np.floor((len(x) - N) / H)) + 1  # Compute number of estimates that will be generated\n",
    "    B = len(F_axis)\n",
    "\n",
    "    p_min = max(int(np.ceil(Fs / F_max)), 1)  # period of maximal frequency in frames\n",
    "    p_max = int(np.ceil(Fs / F_min))  # period of minimal frequency in frames\n",
    "\n",
    "    if p_max > N:\n",
    "        raise Exception(\"N needs to be <= Fs/F_min!\")\n",
    "\n",
    "    rms = np.zeros(M)  # RMS Power\n",
    "    O = np.zeros((2 * B, M))  # every voiced state has an unvoiced state (important for later HMM modeling)\n",
    "    p_orig = np.zeros((len(thresholds), M))\n",
    "    val_orig = np.zeros((len(thresholds), M))\n",
    "\n",
    "    for m in range(M):\n",
    "        # Take a frame from input signal\n",
    "        frame = x[m * H:m * H + N]\n",
    "\n",
    "        # Cumulative Mean Normalized Difference Function\n",
    "        cmndf = cumulative_mean_normalized_difference_function(frame, p_max)\n",
    "\n",
    "        # compute RMS power\n",
    "        rms[m] = np.sqrt(np.mean(frame ** 2))\n",
    "        \n",
    "        # Probabilistic Thresholding with different thresholds\n",
    "        O_m, p_est_thr, val_thr = probabilistic_thresholding(cmndf, thresholds, p_min, p_max, absolute_min_prob, F_axis,\n",
    "                                                             Fs, beta_distr, parabolic_interp=parabolic_interp)\n",
    "\n",
    "        O[:, m] = O_m\n",
    "        p_orig[:, m] = p_est_thr  # store original YIN estimates for later refinement\n",
    "        val_orig[:, m] = val_thr  # store original cmndf value of minimum corresponding to p_est\n",
    "\n",
    "    # normalization (pYIN-Paper, Formula 6)\n",
    "    O[0:B, :] *= voicing_prob\n",
    "    O[B:2 * B, :] = (1 - voicing_prob) * (1 - np.sum(O[0:B, :], axis=0)) / B\n",
    "    \n",
    "    return O, rms, p_orig, val_orig\n",
    "\n",
    "x_pad = np.concatenate((np.zeros(N // 2), x, np.zeros(N // 2)))  # Add zeros for centered estimates\n",
    "\n",
    "thr_idxs = np.arange(len(thresholds))\n",
    "beta_distr = comb(len(thresholds), thr_idxs) * beta(thr_idxs+beta_params[0],\n",
    "                                                    len(thresholds)-thr_idxs+beta_params[1]) / beta(beta_params[0], beta_params[1])\n",
    "B = int(np.log2(F_max / F_min) * (1200 / R))\n",
    "F_axis = F_min * np.power(2, np.arange(B) * R / 1200)  # for quantizing the estimated F0s\n",
    "O, rms, p_orig, val_orig = yin_multi_thr(x_pad, Fs=Fs, N=N, H=H, F_min=F_min, F_max=F_max, thresholds=thresholds, beta_distr=beta_distr, absolute_min_prob=absolute_min_prob, F_axis=F_axis, voicing_prob=voicing_prob)\n",
    "\n",
    "# TODO: Plot nicely\n",
    "plt.pcolormesh(O)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(val_orig.T)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(p_orig.T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d95a7b-de45-4c7b-b4ea-0d7a5790f901",
   "metadata": {},
   "source": [
    "Compute a transition matrix for the Viterbi smoothing of the estimates and run the smmothing to obtain an F0 trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cdb0fd-91d1-4daa-98f3-6cbfbf021aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_transition_matrix(M, triang_distr):\n",
    "    \"\"\"\n",
    "    Compute a transition matrix for PYIN Viterbi.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    M : int\n",
    "        Matrix dimension\n",
    "    triang_distr : ndarray\n",
    "        (Triangular) distribution, defining tolerance for jumps deviating from the main diagonal\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A : ndarray\n",
    "        Transition matrix\n",
    "    \"\"\"\n",
    "    prob_self = 0.99\n",
    "        \n",
    "    A = np.zeros((2*M, 2*M))\n",
    "    max_step = len(triang_distr) // 2\n",
    "\n",
    "    for i in range(M):\n",
    "        if i < max_step:\n",
    "            A[i, 0:i+max_step] = prob_self * triang_distr[max_step - i:-1] / np.sum(triang_distr[max_step - i:-1])\n",
    "            A[i+M, M:i+M+max_step] = prob_self * triang_distr[max_step - i:-1] / np.sum(triang_distr[max_step - i:-1])\n",
    "\n",
    "        if i >= max_step and i < M-max_step:\n",
    "            A[i, i-max_step:i+max_step+1] = prob_self * triang_distr\n",
    "            A[i+M, (i+M)-max_step:(i+M)+max_step+1] = prob_self * triang_distr\n",
    "\n",
    "        if i >= M-max_step:\n",
    "            A[i, i-max_step:M] = prob_self * triang_distr[0:max_step - (i-M)] / np.sum(triang_distr[0:max_step - (i-M)])\n",
    "            A[i+M, i+M-max_step:2*M] = prob_self * triang_distr[0:max_step - (i - M)] / \\\n",
    "                                       np.sum(triang_distr[0:max_step - (i - M)])\n",
    "\n",
    "        A[i, i+M] = 1 - prob_self\n",
    "        A[i+M, i] = 1 - prob_self\n",
    "    \n",
    "    return A\n",
    "\n",
    "def viterbi_log_likelihood(A, C, B_O):\n",
    "    \"\"\"Viterbi algorithm (log variant) for solving the uncovering problem\n",
    "\n",
    "    Notebook: C5/C5S3_Viterbi.ipynb\n",
    "\n",
    "    Args:\n",
    "        A : ndarray\n",
    "            State transition probability matrix of dimension I x I\n",
    "        C : ndarray\n",
    "            Initial state distribution  of dimension I\n",
    "        B_O : ndarray\n",
    "            Likelihood matrix of dimension I x N\n",
    "\n",
    "    Returns:\n",
    "        S_opt : ndarray\n",
    "            Optimal state sequence of length N\n",
    "    \"\"\"\n",
    "    I = A.shape[0]    # Number of states\n",
    "    N = B_O.shape[1]  # Length of observation sequence\n",
    "    tiny = np.finfo(0.).tiny\n",
    "    A_log = np.log(A + tiny)\n",
    "    C_log = np.log(C + tiny)\n",
    "    B_O_log = np.log(B_O + tiny)\n",
    "\n",
    "    # Initialize D and E matrices\n",
    "    D_log = np.zeros((I, N))\n",
    "    E = np.zeros((I, N-1)).astype(np.int32)\n",
    "    D_log[:, 0] = C_log + B_O_log[:, 0]\n",
    "\n",
    "    # Compute D and E in a nested loop\n",
    "    for n in range(1, N):\n",
    "        for i in range(I):\n",
    "            temp_sum = A_log[:, i] + D_log[:, n-1]\n",
    "            D_log[i, n] = np.max(temp_sum) + B_O_log[i, n]\n",
    "            E[i, n-1] = np.argmax(temp_sum)\n",
    "\n",
    "    # Backtracking\n",
    "    S_opt = np.zeros(N).astype(np.int32)\n",
    "    S_opt[-1] = np.argmax(D_log[:, -1])\n",
    "    for n in range(N-2, -1, -1):\n",
    "        S_opt[n] = E[int(S_opt[n+1]), n]\n",
    "\n",
    "    return S_opt\n",
    "\n",
    "max_step_cents = 50  # Pitch jump can be at most 50 cents from frame to frame\n",
    "max_step = int(max_step_cents / R)\n",
    "triang_distr = triang.pdf(np.arange(-max_step, max_step+1), 0.5, scale=2*max_step, loc=-max_step)\n",
    "A = compute_transition_matrix(B, triang_distr)\n",
    "\n",
    "# HMM smoothing\n",
    "C = np.ones((2*B, 1)) / (2*B)  # uniform initialization\n",
    "f0_idxs = viterbi_log_likelihood(A, C.flatten(), O)  # libfmp Viterbi implementation\n",
    "\n",
    "# Obtain F0-trajectory\n",
    "F_axis_extended = np.concatenate((F_axis, np.zeros(len(F_axis))))\n",
    "f0 = F_axis_extended[f0_idxs]\n",
    "\n",
    "# Suppress low power estimates\n",
    "f0[0] = 0  # due to algorithmic reasons, we set the first value unvoiced\n",
    "f0[rms < 0.01] = 0\n",
    "\n",
    "# confidence\n",
    "O_norm = O[:, np.arange(O.shape[1])]/np.max(O, axis=0)\n",
    "conf = O_norm[f0_idxs, np.arange(O.shape[1])]\n",
    "\n",
    "# TODO: nice plot\n",
    "plt.plot(f0)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(conf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993aceb0-c381-4861-9613-243c68c1d301",
   "metadata": {},
   "source": [
    "Finally, the estimates can be refined by choosing the closest original YIN estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bf8510-4dad-4f63-a254-a760214b5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_estimates_yin(f0, p_orig, val_orig, Fs, tol):\n",
    "    \"\"\"\n",
    "    Refine estimates using YIN CMNDF information.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f0 : ndarray\n",
    "        F0 in Hz\n",
    "    p_orig : ndarray\n",
    "        Original lag as computed by YIN\n",
    "    val_orig : ndarray\n",
    "        Original CMNDF values as computed by YIN\n",
    "    Fs : float\n",
    "        Sampling frequency\n",
    "    tol : float\n",
    "        Tolerance for refinements in cents\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    f0_refined : ndarray\n",
    "        Refined F0-trajectory\n",
    "    \"\"\"\n",
    "    f0_refined = np.zeros_like(f0)\n",
    "    voiced_idxs = np.where(f0 > 0)[0]\n",
    "\n",
    "    f_orig = Fs / p_orig\n",
    "\n",
    "    # find closest original YIN estimate, maximally allowed absolute deviation: R (quantization error)\n",
    "    for m in voiced_idxs:\n",
    "        diff_cents = np.abs(1200 * np.log2(f_orig[:, m] / f0[m]))\n",
    "        candidate_idxs = np.where(diff_cents < tol)[0]\n",
    "\n",
    "        if not candidate_idxs.size:\n",
    "            f0_refined[m] = f0[m]\n",
    "        else:\n",
    "            f0_refined[m] = f_orig[candidate_idxs[np.argmin(val_orig[candidate_idxs, m])], m]\n",
    "\n",
    "    return f0_refined\n",
    "\n",
    "f0_refined = refine_estimates_yin(f0, p_orig, val_orig, Fs, R)\n",
    "t = np.arange(O.shape[1]) * H / Fs  # Time axis\n",
    "\n",
    "# TODO: nice plot\n",
    "plt.plot(f0)\n",
    "plt.plot(f0_refined)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
